{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ee6568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0d1aa1",
   "metadata": {},
   "source": [
    "## Pages retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a870cdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def url_checker(url):\n",
    "    try:\n",
    "        get = requests.get(url)  # get url\n",
    "        if get.status_code == 200:  # request succeeds \n",
    "            return 1, get.content\n",
    "        else:\n",
    "            return 0, ''\n",
    "\n",
    "    #Exception\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # print URL with Errs\n",
    "        raise SystemExit(f\"{url}: is Not reachable \\nErr: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ddc8083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finded 585, cur ID: 189499: 100%|███████████| 2000/2000 [11:38<00:00,  2.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# results = {}\n",
    "# search_range = np.arange(188500 - 1000, 188500 + 1000)\n",
    "# progress_bar = tqdm(search_range)\n",
    "# num_finded_pages = 0\n",
    "\n",
    "# for page_id in progress_bar:\n",
    "#     cur_http = f\"https://old.gu.spb.ru/{page_id}/eservice/\"\n",
    "#     status, text = url_checker(cur_http)\n",
    "    \n",
    "#     # dump page\n",
    "#     if status:\n",
    "#         results[cur_http] = text\n",
    "#         num_finded_pages += 1\n",
    "        \n",
    "#     progress_bar.set_description(f\"Finded {num_finded_pages}, cur ID: {page_id}\")    \n",
    "#     sleep(0.1)\n",
    "# #     print(page_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "178d820c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['parsing_results.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib.dump(results, 'parsing_results.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5653b5",
   "metadata": {},
   "source": [
    "## Pages parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b196f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = joblib.load('parsing_results.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d86dbf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['https://old.gu.spb.ru/188411/eservice/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "89ce1e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\"Общее описание\",\n",
    "        \"Результат предоставления\",\n",
    "        \"Срок предоставления\",\n",
    "        \"Заявители\",\n",
    "        \"Порядок действий\",\n",
    "        \"Документы\"\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4ce025bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "и ребенка — при родах вне медицинской\n"
     ]
    }
   ],
   "source": [
    "my_str = \"и ребенка\\xa0—\\xa0при родах вне медицинской\"\n",
    "print(my_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c14baa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "75687724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'и ребенка — при родах вне медицинской'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = re.compile(r'[\\n\\r\\t]')\n",
    "regex2 = re.compile(r'[\\xa0]')\n",
    "regex.sub('', my_str)\n",
    "regex2.sub(' ', my_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f93e5cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_url(bytes_html, relevant_tags=tags):\n",
    "    regex = re.compile(r'[\\n\\r\\t\\xa0]')\n",
    "    \n",
    "    soup = bs(bytes_html, 'html.parser')\n",
    "    \n",
    "    h1_tag = soup.find('h1').find('span').text.strip()\n",
    "    h1_tag = regex.sub('', h1_tag)\n",
    "    all_templates = []\n",
    "    \n",
    "    # parse h2\n",
    "    all_h2 = soup.find_all('h2')\n",
    "    for cur_h2 in all_h2:\n",
    "        if cur_h2.text in relevant_tags:\n",
    "            text_between_h2 = []\n",
    "            cur_tag = cur_h2.find_next_sibling()\n",
    "            while cur_tag:\n",
    "                text_between_h2.append(str(cur_tag))\n",
    "                cur_tag = cur_tag.find_next_sibling()\n",
    "\n",
    "            text_between_h2 = '\\n'.join(text_between_h2) \n",
    "            \n",
    "            # parse h3\n",
    "            h2_soup = bs(text_between_h2, 'html.parser')\n",
    "            all_h3 = h2_soup.find_all('h3')\n",
    "            for cur_h3 in all_h3:\n",
    "                text_between_h3 = []\n",
    "                cur_tag = cur_h3.find_next_sibling()\n",
    "                while cur_tag:\n",
    "                    if cur_tag.name == 'h3':\n",
    "                        joined_text = \"\\n\".join(text_between_h3)\n",
    "                        template = \"\\n\".join([f\"Услуга: {h1_tag}\",\n",
    "                                              f\"Заголовок: {regex.sub('', cur_h2.text)}\",\n",
    "                                              f\"Подраздел: {regex.sub('', cur_h3.text)}\",\n",
    "                                              f\"Текст: {regex.sub('', joined_text)}\"\n",
    "                                             ])\n",
    "                        all_templates.append(template)\n",
    "                        text_between_h3 = []\n",
    "                        break\n",
    "                    else:\n",
    "                        text_between_h3.append(cur_tag.text)\n",
    "                        cur_tag = cur_tag.find_next_sibling()\n",
    "                if text_between_h3:\n",
    "                    joined_text = \"\\n\".join(text_between_h3)\n",
    "                    template = \"\\n\".join([f\"Услуга: {h1_tag}\",\n",
    "                                          f\"Заголовок: {regex.sub('', cur_h2.text)}\",\n",
    "                                          f\"Подраздел: {regex.sub('', cur_h3.text)}\",\n",
    "                                          f\"Текст: {regex.sub('', joined_text)}\"\n",
    "                                         ])\n",
    "                    all_templates.append(template)                    \n",
    "            if not all_h3:\n",
    "                template = \"\\n\".join([f\"Услуга: {h1_tag}\",\n",
    "                                      f\"Заголовок: {regex.sub('', cur_h2.text)}\",\n",
    "                                      f\"Текст: {regex.sub('', h2_soup.text)}\"\n",
    "                                     ])\n",
    "                all_templates.append(template)\n",
    "                \n",
    "    return all_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "198f7980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '12', '2']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['1', '2']\n",
    "a.extend(['12', '2'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5cce9c7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 585/585 [00:12<00:00, 47.84it/s]\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "for http, document in tqdm(results.items()):\n",
    "    chunks.extend(parse_url(document, relevant_tags=tags))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "36d1bab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 585/585 [00:12<00:00, 47.72it/s]\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "for http, document in tqdm(results.items()):\n",
    "    chunks.extend(parse_url(document, relevant_tags=tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "027ec153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://old.gu.spb.ru/189497/eservice/'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(results.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f5ad78fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "\n",
    "# # field names\n",
    "# fields = ['Context']\n",
    "\n",
    "# with open('mfc_context_chunks.csv', 'w') as f:\n",
    "#     # using csv.writer method from CSV package\n",
    "#     write = csv.writer(f)\n",
    "#     write.writerow(fields)\n",
    "#     write.writerows(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "cf01b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(chunks, columns=['Context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c243c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('mfc_context_chunks_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed60f445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hack",
   "language": "python",
   "name": "hack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
